{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 什么是PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch是一个基于python的科学计算包，主要针对两类人群：\n",
    "* 作为NumPy的替代品，可以利用GPU的性能进行计算\n",
    "* 作为一个高灵活性、速度快的深度学习平台"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Tensor` 类似于 `Numpy` 的 `ndarray` ，但还可以在GPU上使用来加速计算。\n",
    "\n",
    "`Tensor` 是 `PyTorch` 中重要的数据结构，可认为是一个高维数组。它可以是 `一个数（标量）` 、 `一维数组（向量）` 、 `二维数组（矩阵）` 以及更 `高维的数组` 。Tensor和Numpy的ndarrays类似，但Tensor可以使用GPU进行加速。Tensor的使用和Numpy及Matlab的接口十分相似。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**导入 `PyTorch` 包**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:41:54.096567Z",
     "start_time": "2019-06-03T02:41:53.289424Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**创建一个没有初始化的 `5 * 3` 矩阵**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:41:54.106578Z",
     "start_time": "2019-06-03T02:41:54.099350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**创建一个随机初始化的 `5 * 3` 矩阵**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:41:54.117246Z",
     "start_time": "2019-06-03T02:41:54.109068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3262, 0.8605, 0.3583],\n",
      "        [0.6820, 0.7553, 0.2888],\n",
      "        [0.2928, 0.7479, 0.0470],\n",
      "        [0.5299, 0.1583, 0.8232],\n",
      "        [0.1096, 0.2576, 0.6104]])\n"
     ]
    }
   ],
   "source": [
    " x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**构造一个全部为 `0` 且数据类型为 `long` 的 `5 * 3` 矩阵**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:41:54.127253Z",
     "start_time": "2019-06-03T02:41:54.121605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**直接从数据构造张量**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:41:54.137634Z",
     "start_time": "2019-06-03T02:41:54.130686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**根据已有的 `tensor` 建立新的 `tensor`**\n",
    "\n",
    "除非用户提供新的值，否则这些方法将重用输入张量的属性，例如 `dtype` 等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:41:54.146455Z",
     "start_time": "2019-06-03T02:41:54.139589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# new_* methods take in sizes\n",
    "x = x.new_ones(5, 3, dtype=torch.double)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:41:54.154969Z",
     "start_time": "2019-06-03T02:41:54.148416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3302,  0.2553, -0.5273],\n",
      "        [ 0.0882,  0.2170, -0.4866],\n",
      "        [-0.2964, -0.1960, -1.3247],\n",
      "        [-0.3479,  1.3610, -0.4364],\n",
      "        [ 0.5204,  1.7581,  0.2340]])\n"
     ]
    }
   ],
   "source": [
    "# 重载dtype，结果有相同的size\n",
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:41:54.165387Z",
     "start_time": "2019-06-03T02:41:54.157407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 注意：<br>\n",
    "`torch.Size` 本质上还是 `tuple`，所以支持tuple的一切操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T00:59:34.517297Z",
     "start_time": "2019-06-03T00:59:34.513240Z"
    }
   },
   "source": [
    "## 运算 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**加法：形式1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:41:54.178793Z",
     "start_time": "2019-06-03T02:41:54.168174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8451,  0.6908, -0.3946],\n",
      "        [ 0.4987,  0.2943, -0.1693],\n",
      "        [-0.1301,  0.5376, -0.6440],\n",
      "        [ 0.2824,  1.9215, -0.0975],\n",
      "        [ 0.9350,  1.8784,  0.8255]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**加法：形式2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:41:54.188678Z",
     "start_time": "2019-06-03T02:41:54.181780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8451,  0.6908, -0.3946],\n",
      "        [ 0.4987,  0.2943, -0.1693],\n",
      "        [-0.1301,  0.5376, -0.6440],\n",
      "        [ 0.2824,  1.9215, -0.0975],\n",
      "        [ 0.9350,  1.8784,  0.8255]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**加法：给定一个输出张量作为参数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:41:54.198990Z",
     "start_time": "2019-06-03T02:41:54.191272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8451,  0.6908, -0.3946],\n",
      "        [ 0.4987,  0.2943, -0.1693],\n",
      "        [-0.1301,  0.5376, -0.6440],\n",
      "        [ 0.2824,  1.9215, -0.0975],\n",
      "        [ 0.9350,  1.8784,  0.8255]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**加法：原位/原地操作 `in-place`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:41:54.210725Z",
     "start_time": "2019-06-03T02:41:54.201765Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8451,  0.6908, -0.3946],\n",
      "        [ 0.4987,  0.2943, -0.1693],\n",
      "        [-0.1301,  0.5376, -0.6440],\n",
      "        [ 0.2824,  1.9215, -0.0975],\n",
      "        [ 0.9350,  1.8784,  0.8255]])\n"
     ]
    }
   ],
   "source": [
    "# adds x to y\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 注意：<br>\n",
    "任何一个 `in-place` 改变张量的操作后面都固定了一个 `_` 。例如 `x.copy_(y)` 、 `x.t_()` 将更改 `x`。<br>\n",
    "但 `torch.add(x, y)` 和 `(x + y)` 返回一个新的 `Tensor`，原 `x` 和 `y` 不变。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**索引操作**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:41:54.218093Z",
     "start_time": "2019-06-03T02:41:54.213223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2553,  0.2170, -0.1960,  1.3610,  1.7581])\n"
     ]
    }
   ],
   "source": [
    "print(x[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**改变形状：`torch.view`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:41:54.225939Z",
     "start_time": "2019-06-03T02:41:54.220426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**仅包含一个元素的 tensor**\n",
    "\n",
    "可以使用 `.item()` 来得到对应的python数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:41:54.234177Z",
     "start_time": "2019-06-03T02:41:54.228436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2229])\n",
      "1.2229341268539429\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 更多的运算操作，包括转置，索引，切片，数学运算，线性代数，随机数等，[参阅这里](https://pytorch.org/docs/stable/torch.html)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy 桥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 将一个Torch张量转换为一个NumPy数组是轻而易举的事情，反之亦然。\n",
    "* Torch张量和NumPy数组将共享它们的底层内存位置，而且几乎不会消耗什么资源, 但是更改一个将更改另一个。\n",
    "* 对于Tensor不支持的操作，可以先转为Numpy数组处理，之后再转回Tensor。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**将 `Torch` 的 `Tensor` 转换为 `Numpy数组`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:41:54.241113Z",
     "start_time": "2019-06-03T02:41:54.236042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:41:54.250683Z",
     "start_time": "2019-06-03T02:41:54.244054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:41:54.263006Z",
     "start_time": "2019-06-03T02:41:54.256696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**将 `Numpy` 数组转换为 `Torch` 的 `张量`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:41:54.268948Z",
     "start_time": "2019-06-03T02:41:54.265786Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:41:54.277178Z",
     "start_time": "2019-06-03T02:41:54.271714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:41:54.287427Z",
     "start_time": "2019-06-03T02:41:54.282313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "b = torch.from_numpy(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:41:54.295730Z",
     "start_time": "2019-06-03T02:41:54.289673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> CPU上的所有张量(CharTensor除外)都支持转换为NumPy以及由NumPy转换回来。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**此外在 `PyTorch` 中还有一个和 `np.array` 很类似的接口: `torch.tensor`, 二者的使用十分类似。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:41:54.302504Z",
     "start_time": "2019-06-03T02:41:54.297973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 4])\n"
     ]
    }
   ],
   "source": [
    "# 新建一个包含 3，4 两个元素的tensor\n",
    "tensor = torch.tensor([3, 4])\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:41:54.308700Z",
     "start_time": "2019-06-03T02:41:54.304604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "scalar = torch.tensor(3)\n",
    "print(scalar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要注意的是，torch.tensor()总是会进行数据拷贝，新tensor和原来的数据不再共享内存。\n",
    "\n",
    "所以如果想共享内存的话，建议使用torch.from_numpy()或者tensor.detach()来新建一个tensor, 二者共享内存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:41:54.317109Z",
     "start_time": "2019-06-03T02:41:54.311161Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old_tensor([3, 4]), New_tensor([1111,    4])\n"
     ]
    }
   ],
   "source": [
    "old_tensor = tensor\n",
    "new_tensor = old_tensor.clone()\n",
    "new_tensor[0] = 1111\n",
    "print(\"Old_{}, New_{}\".format(old_tensor, new_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:41:54.323864Z",
     "start_time": "2019-06-03T02:41:54.319312Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old_tensor([1111,    4]), New_tensor([1111,    4])\n"
     ]
    }
   ],
   "source": [
    "new_tensor = old_tensor.detach()\n",
    "new_tensor[0] = 1111\n",
    "print(\"Old_{}, New_{}\".format(old_tensor, new_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA上的张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "张量可以使用 `.to` 方法移动到任何设备上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:41:54.334274Z",
     "start_time": "2019-06-03T02:41:54.326376Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell only if CUDA is available\n",
    "# 将使用`torch.device`来将tensor移入和移出GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # 直接在GPU上创建tensor\n",
    "    x = x.to(device)                       # 或者使用`.to(\"cuda\")`方法\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # `.to`也能在移动时改变dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:41:54.347263Z",
     "start_time": "2019-06-03T02:41:54.338569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.6225,  2.2576,  1.2856,  1.8153,  1.0629,  1.7938,  1.2089,  2.2448,\n",
      "         1.0687,  0.4957, -1.2125,  0.8802,  2.0282, -1.3848,  2.5986,  1.4389])\n"
     ]
    }
   ],
   "source": [
    "# 在不支持CUDA的机器下，下一步还是在CPU上运行\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "z = x + y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:40:46.789585Z",
     "start_time": "2019-06-03T02:40:46.782274Z"
    }
   },
   "source": [
    "此外，还可以使用 `tensor.cuda()` 的方式将tensor拷贝到gpu上，但是这种方式不太推荐。\n",
    "\n",
    "此处可能GPU运算的速度并未提升太多，这是因为x和y太小且运算也较为简单，而且将数据从内存转移到显存还需要花费额外的开销。\n",
    "\n",
    "GPU的优势需在大规模数据和复杂运算下才能体现出来。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
